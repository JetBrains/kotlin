# Remote Kotlin compilation daemon
This README.md document describes the current state of the remote compilation daemon developed during an internship.

## Server & Client Communication Overview
When compilation is invoked, a stream is opened between the client and server and kept open until the compilation is finished. Client and server communicate using the following messages:
- `CLIENT` <----> `SERVER`
 - -----> `CompilationMetadata` - client sends compilation metadata together with `CompilationOptions`
 - -----> `FileTransferRequest` - client asks server if a particular file is available in cache based on its fingerprint, this is sent for every file required for compilation
 - <----- `FileTransferResponse` - answer for client's request
 - -----> `FileChunk` - if server does not have a requested file in cache, a client starts sending chunks of required files, based on selected chunking strategy
 - once all files are present and compilation arguments prepared, compilation is invoked
 - <----- `CompilerMessage` - server streams compiler messages to the client as they come
 - <----- `CompilationResult` - server sends exit code and source of the result to a client
 - <----- `FileChunk` - server sends file chunks of a compilation result to a client

Definitions of these objects can be found in the [model](src/main/kotlin/model) folder.

### Incremental compilation
When using incremental compilation, the communication process is slightly modified. Instead of requesting the transfer of all files, only the files that have changed since the last compilation are sent without a request because we expect that other files are already present on the server from a previous compilation run. If the server detects that some files are missing, it can request them from the client by sending a [MissingArtifactsRequest](src/main/kotlin/model/MissingArtifactsRequest.kt).

Also, classpath snapshots are sent with every request, and they are not cached. In addition to class files, the server also sends the entire IC cache to a client.


## File Chunking
The reason for supporting file chunking is that we do not want to send all files at once.  For large files, it is undesirable to load them entirely into memory as this may cause memory issues. Since `gRPC` limits a single message to 4 MB, the file  
[FixedSizeChunkingStrategy.kt](src/main/kotlin/common/FileChunkingStrategy.kt) uses 4 MB as the default chunk size. This means that every file smaller than 4 MB will be sent as a single message, while larger files will be split into 4 MB chunks. The `4MB` gRPC setting can be overridden.

Before we sent directories, they are converted and into a `.tar` file and treated as a standard file, however, directory fingerprint is computed from directory, before `.tar` conversion.

## Implementation
We can split the implementation into two parts, client and sever.

### Server side
The server implementation of communication is located in file
[RemoteCompilationServiceImpl.kt](src/main/kotlin/server/core/RemoteCompilationServiceImpl.kt). 

The implementation uses objects from the  
[model](src/main/kotlin/model) folder. The primary reason for this is to ensure that the logic is not tightly coupled to any specific protocol. Files in the [model](src/main/kotlin/model) folder also contain extension functions that convert our local objects into the objects generated by the `gRPC` library.

Another reason for using these custom objects is that it may be challenging to work with the objects currently used by the `Kotlin Daemon`. There is no one-to-one correspondence in local and remote communication. Additionally, `kotlinx-rpc` requires working with `@Serialization` annotations. Applying these annotations to existing objects can be problematic, and one may end up in a vicious circle of errors when trying to avoid modifying large portions of code.

###  Client side
Client implementation is located in the file [RemoteCompilationClient.kt](src/main/kotlin/client/core/RemoteCompilationClient.kt). This file follows the same principle as a server implementation, the logic is independent of the protocol. In case of `gRPC`, we convert all `gRPC` generated objects in file [GrpcRemoteCompilationServiceClient.kt](src/main/kotlin/client/grpc/GrpcRemoteCompilationServiceClient.kt). When using `kotlinx-rpc` we work directly with the objects from the [model](src/main/kotlin/model) folder.


## Kotlin Compilation
The actual compilation is executed in the class  
[InProcessCompilerService.kt](src/main/kotlin/server/core/InProcessCompilerService.kt). The main function responsible for this is `compileImpl`. This function was taken from  
[CompileServiceImpl.kt](../../../compiler/daemon/src/org/jetbrains/kotlin/daemon/CompileServiceImpl.kt).

The reason the existing `Kotlin Daemon` is not being used for compilation is that when invoking compilation using the `Kotlin Daemon`, all arguments must be passed to the `Kotlin Daemon` process in which the compiler runs. This inter-process communication is carried out via the `RMI` protocol, which is outdated. The goal is to run all compilations in a single process to avoid the overhead of inter-process communication.

## Docker Image
The `remote-daemon` module contains two Dockerfiles, namely [Dockerfile](Dockerfile) and [Dockerfile2](Dockerfile2).

In the [Dockerfile](Dockerfile) file, there is an attempt to create a more serious Dockerfile by properly copying the required files and compiling them.
The process of building image from [Dockerfile](Dockerfile) was really slow, and I could not make it work, so for the time being I resorted to workaround and used [Dockerfile2](Dockerfile2). In this case, compilation is performed on a local machine and resulting `.jar` is moved to the Docker image.

Docker images are stored under in the [Space registry](https://jetbrains.team/p/kotlin-build-tools/packages/container/remote-kotlin-daemon-containers) under the `Kotlin Build Tools`.

Few useful commands:
- get the jar file\
`./gradlew --stop && ./gradlew clean && ./gradlew :kotlin-remote-daemon:installDist`
- build & push Docker image to the Space registry\
`docker buildx build --platform linux/amd64,linux/arm64 --progress=plain -f compiler/daemon/remote-daemon/Dockerfile2 -t registry.jetbrains.team/p/kotlin-build-tools/remote-kotlin-daemon-containers/kotlin-remote-daemon-workaround:latest --push .`
- build Docker image for local testing\
`docker build --platform=linux/amd64 -t kotlin-daemon:latest -f compiler/daemon/remote-daemon/Dockerfile2 .`
- pull the image from the Space registry\
`docker pull registry.jetbrains.team/p/kotlin-build-tools/remote-kotlin-daemon-containers/kotlin-remote-daemon-workaround:latest`


When building image using [Dockerfile2](Dockerfile2), remember to build again the `.jar` before with the latest changes. It is a common source of issues.

### Kubernetes deployment
[Intellij Console](https://console.intellij.net/) offers three ways how to deploy apps to Kubernetes, namely `Google JIB`, `Skaffold + kubectl apply`, `Pure Skaffold`. As I did not want to deal with `Skaffold` and `TeamCity` stuff I decided to deploy directly from my local machine only using `Helm`. I did it with the help of this [guide](https://github.com/JetBrains/kotlin-native/blob/master/samples/remote-daemon/README.md).

The existing helm chart included in the guide has one flaw. The `imagePullPolicy` is set to `IfNotPresent` which means that `k8s` deployment would not pull the image from the registry even when newer image is available.

To overcome this, the original `Helm` chart was unpacked to [compiler/daemon/remote-daemon/k8s/simple-app-customized] directory where `imagePullPolicy: Always` was added to the [values.yaml](k8s/simple-app-customized/values.yaml) file.

Also, configuration for `gRPC` and `WebSockets` protocols needs to be slightly different, that is to reason why we have two separate files, [grpc_values.yaml](k8s/grpc_values.yaml) and [websockets_values.yaml](k8s/websockets_values.yaml). Do diff to see the differences.

Useful commands for deployment using customized `Helm` chart:
- deploy `gPRC` version
  - `helm install remote-kotlin-daemon-grpc compiler/daemon/remote-daemon/k8s/simple-app-customized -f compiler/daemon/remote-daemon/k8s/grpc_values.yaml`
- remove `gRPC` version
  - `helm uninstall remote-kotlin-daemon-grpc`
- deploy `WebSockets` version
  - `helm install remote-kotlin-daemon-websockets compiler/daemon/remote-daemon/k8s/simple-app-customized -f compiler/daemon/remote-daemon/k8s/websockets_values.yaml`
- remove `WebSockets` version
  - `helm uninstall remote-kotlin-daemon-websockets`

In case any configuration is not working because a client cannot connect to the server, this port-forwarding command might help:
`kubectl port-forward svc/remote-kotlin-daemon-websockets 8080:8000 -n remote-compilation-ns`. 

Sometimes the connection does not work right away after deployment because of some `DNS` related issues. Probably it just takes some time to propagate the changes.

## Cache
For caching we use a standard filesystem with the following folder structure:
- `/storage`
  - `/cache`
    - `/artifacts`
      - `/<file-fingerprint>`
    - `/tmp`

Caching in our app is primarily content-based. For computing the fingerprint, we use the `SHA-256` function. We cache multiple types of artifacts, namely:
- source files 
- compiler plugins
- compiler outputs
- dependencies (.class, .jar, directories)

Fingerprints for source files and compiler plugins are calculated only using the file content.

In the case of a folder, we also hash the relative file paths of all files in the folder. The file paths are sorted alphabetically to preserve the unique hash.

Hashing compiler outputs is a bit more complicated. We cannot compute the fingerprint directly from the produced class files, we would not be able to retrieve the result from the cache without actually compiling it before and obtaining the hash from produced class files. Instead, we compute the fingerprint from the source files and compiler arguments.

Some artifacts are stored in two ways. For example, some compilation tasks produce `.jar` file. This file can be stored as a dependency, that means that we just compute the fingerprint of the file content. However, the same `.jar` file can also be stored as a compiler output. This means that we also compute fingerprint of source files and compiler arguments that produced this `.jar` file. Then in `\artifacts` folder we create a symlink to the original `.jar` file stored as dependency (fingerprint computed only using source file content).

## Auth
The current solution includes a simple authentication mechanism but only in the gRPC implementation.

1. The client encodes `username:password` using Base64 and sends it in the `Authorization` header, check [BasicHTTPAuthClient.kt](src/main/kotlin/client/core/BasicHTTPAuthClient.kt).
2. The server verifies the credential against the entries in [auth.json](src/main/kotlin/server/auth/auth.json).
3. If the credential is valid, the server retrieves the corresponding `userId` from [uuid.json](src/main/kotlin/server/auth/uuid.json).
4. This `userId` is then used to create a dedicated compilation workspace directory for that user.

Of course, this approach is very rudimentary and not properly secure. It would make sense to revisit authentication once the protocol has been chosen and the solution is ready to be integrated into the existing infrastructure.

## Compilation Workspace
Compilation workspace is a directory that contains all files that are needed for a compilation task. The directory structure is as follows:
- `/storage`
  - `/workspaces`
    - `/<user-id>`
      - `/<project-name>`
        - `/<client-absolute-path>`

Once a file is available for compilation, regardless of whether it was received over the network or retrieved from a cache, it is copied to the compilation workspace. Maybe a potential performance improvement would be to create a symlink to the file instead of copying it. After the files are copied, it is also necessary to modify all paths in the compiler arguments and compilation options.

For example, if an absolute path on the client side is `/Users/michal.svec/Desktop/kotlin/compiler/backend/src/org/jetbrains/kotlin/codegen/inline/FieldRemapper.kt`, this path will be mapped to `/storage/workspaces/<user-id>/<project-name>/Users/michal.svec/Desktop/kotlin/compiler/backend/src/org/jetbrains/kotlin/codegen/inline/FieldRemapper.kt`. This preservation of the original file structure from the client side makes the process less error-prone. The file paths themselves are also important. For example, a file path might be contained in a compiler message. When sending this message back to the client, we can then retrieve the original client path.

The `tmp` directory serves as temporary storage and is used for storing files that were just reconstructed from chunks. Afterward, these files are moved to the cache or a specific compilation workspace if needed. Potentially, we could eliminate the `tmp` directory by directly computing the hash from file chunks. Currently, however, we only support computing hashes from files.

## Known Issues & Missing Features
- **compilation target**
    - currently, only the `JVM` target is supported
- **compiler plugins**
    - only specific versions of compiler plugins are supported
    - there is a one-to-one correspondence between compiler plugins and compiler version
        - this means that providing an incompatible compiler plugin to the compiler will result in failure
        - the current workaround is located in the [libsworkaround](src/main/kotlin/server/libsworkaround) folder
          - if there is a certain plugin in compiler arguments, its path will be rewritten by the plugin located in the [libsworkaround](src/main/kotlin/server/libsworkaround) folder
    - probably proper solution would be to have multiple JVM processes with different versions of compiler, and the request should be roted to the appropriate process
- **incremental compilation limits**
    - currently we are computing snapshot only on a client
    - probably it would be good to compute them on a sever
    - possibly we could consider caching them
- **`jdk-home` argument**
    - the Kotlin compiler accepts a `jdk-home` argument
    - however, sending the entire JDK to the server is impractical due to its large size
    - an alternative approach that was considered was sending only the parts of the `JDK` that change across versions, however, this approach is fragile since there is no standardized method for doing so
    - the current workaround removes `jdk-home` from the compiler arguments, `JDK home` will be inferred from `JAVA_HOME` environment variable
      - if we install the latest `JDK` on the server and then with help of `jvm-target` tag we should be able to compile projects even for older versions of `JDK`

## How To Run
All testings have been conducted on the [Ktor](https://github.com/ktorio/ktor) project. Since this remote compilation server is not integrated with the existing infrastructure, we needed to establish a method for running large compilation tasks. The process is as follows:

### Standard compilation
1. clone the [Ktor](https://github.com/ktorio/ktor) repository
    - the last-tested commit ID: `af24a5a1a663d6c3c4fe36360a565fe17461b2d`
    - newer versions will likely fail due to incompatible compiler plugins
2. configure the build script
    - open the `build.gradle.kts` file in the Ktor project
    - add the following code to the file:
   ```kotlin
   tasks.register("assembleAllKotlin") {
       allprojects {
           dependsOn(
               tasks
                   .withType<org.jetbrains.kotlin.gradle.tasks.KotlinCompile>()
                   .matching { !it.name.lowercase().contains("android") }
           )
       }
   }
   ```
    - `android` related tasks are excluded as they require the `Android SDK` to be installed

3. generate compilation output
    - execute the following command to output all Kotlin compilation tasks along with compiler arguments to a file:
   ```bash
   ./gradlew --stop && ./gradlew clean && ./gradlew assembleAllKotlin --no-configuration-cache --rerun --no-build-cache --refresh-dependencies -Pkotlin.internal.compiler.arguments.log.level=warning -Pkotlin.incremental=false > output
   ```
4. copy the absolute path of the generated output file
5. configure the [Benchmark.kt](/src/main/kotlin/benchmark/Benchmark.kt)
    - compilation of the Ktor project can be invoked in the file [Benchmark.kt](/src/main/kotlin/benchmark/Benchmark.kt)
    - paste the copied path into the `getTask` function located within the `main()` function
    - `getTask()` is a utility function that will extract all required information from the file and return it as a `List<Task>` object
    - remember to change the `host` and `port` values to match your setup
6. change the current working directory (CWD) of [Benchmark.kt](/src/main/kotlin/benchmark/Benchmark.kt) configuration to `/kotlin/compiler/daemon/remote-daemon`
7. the main function is now ready to be run
# Remote Kotlin compilation daemon
This README.md document describes the current state of the remote compilation daemon developed during an internship.

## Server & Client Communication Overview
When compilation is invoked, a stream is opened between the client and server and kept open until the compilation is finished. Client and server communicate using the following messages:
- `CLIENT` <----> `SERVER`
- -----> `CompilationMetadata` - client sends compilation metadata together with `CompilationOptions`
- -----> `FileTransferRequest` - client asks server if a particular file is available in cache based on its fingerprint, this is sent for every file required for compilation
- <----- `FileTransferResponse` - answer for client's request
- -----> `FileChunk` - if server does not have a requested file in cache, a client starts sending chunks of required files, based on selected chunking strategy
- once all files are present and compilation arguments prepared, compilation is invoked
- <----- `CompilerMessage` - server streams compiler messages to the client as they come
- <----- `CompilationResult` - server sends exit code and source of the result to a client
- <----- `FileChunk` - server sends file chunks of a compilation result to a client

Definitions of these objects can be found in the [model](src/main/kotlin/model) folder.

### Incremental compilation
When using incremental compilation, the communication process is slightly modified. Instead of requesting the transfer of all files, only the files that have changed since the last compilation are sent without a request because we expect that other files are already present on the server from a previous compilation run. If the server detects that some files are missing, it can request them from the client by sending a [MissingArtifactsRequest](src/main/kotlin/model/MissingArtifactsRequest.kt).

Also, classpath snapshots are sent with every request, and they are not cached. In addition to class files, the server also sends the entire IC cache to a client.


## File Chunking
The reason for supporting file chunking is that we do not want to send all files at once.  For large files, it is undesirable to load them entirely into memory as this may cause memory issues. Since `gRPC` limits a single message to 4 MB, the file  
[FixedSizeChunkingStrategy.kt](src/main/kotlin/common/FileChunkingStrategy.kt) uses 4 MB as the default chunk size. This means that every file smaller than 4 MB will be sent as a single message, while larger files will be split into 4 MB chunks. The `4MB` gRPC setting can be overridden.

Before we sent directories, they are converted and into a `.tar` file and treated as a standard file, however, directory fingerprint is computed from directory, before `.tar` conversion.

## Implementation
We can split the implementation into two parts, client and sever.

### Server side
The server implementation of communication is located in file
[RemoteCompilationServiceImpl.kt](src/main/kotlin/server/core/RemoteCompilationServiceImpl.kt).

The implementation uses objects from the  
[model](src/main/kotlin/model) folder. The primary reason for this is to ensure that the logic is not tightly coupled to any specific protocol. Files in the [model](src/main/kotlin/model) folder also contain extension functions that convert our local objects into the objects generated by the `gRPC` library.

Another reason for using these custom objects is that it may be challenging to work with the objects currently used by the `Kotlin Daemon`. There is no one-to-one correspondence in local and remote communication. Additionally, `kotlinx-rpc` requires working with `@Serialization` annotations. Applying these annotations to existing objects can be problematic, and one may end up in a vicious circle of errors when trying to avoid modifying large portions of code.

###  Client side
Client implementation is located in the file [RemoteCompilationClient.kt](src/main/kotlin/client/core/RemoteCompilationClient.kt). This file follows the same principle as a server implementation, the logic is independent of the protocol. In case of `gRPC`, we convert all `gRPC` generated objects in file [GrpcRemoteCompilationServiceClient.kt](src/main/kotlin/client/grpc/GrpcRemoteCompilationServiceClient.kt). When using `kotlinx-rpc` we work directly with the objects from the [model](src/main/kotlin/model) folder.


## Kotlin Compilation
The actual compilation is executed in the class  
[InProcessCompilerService.kt](src/main/kotlin/server/core/InProcessCompilerService.kt). The main function responsible for this is `compileImpl`. This function was taken from  
[CompileServiceImpl.kt](../../../compiler/daemon/src/org/jetbrains/kotlin/daemon/CompileServiceImpl.kt).

The reason the existing `Kotlin Daemon` is not being used for compilation is that when invoking compilation using the `Kotlin Daemon`, all arguments must be passed to the `Kotlin Daemon` process in which the compiler runs. This inter-process communication is carried out via the `RMI` protocol, which is outdated. The goal is to run all compilations in a single process to avoid the overhead of inter-process communication.

## Docker Image
The `remote-daemon` module contains two Dockerfiles, namely [Dockerfile](Dockerfile) and [Dockerfile2](Dockerfile2).

In the [Dockerfile](Dockerfile) file, there is an attempt to create a more serious Dockerfile by properly copying the required files and compiling them.
The process of building image from [Dockerfile](Dockerfile) was really slow, and I could not make it work, so for the time being I resorted to workaround and used [Dockerfile2](Dockerfile2). In this case, compilation is performed on a local machine and resulting `.jar` is moved to the Docker image.

Docker images are stored under in the [Space registry](https://jetbrains.team/p/kotlin-build-tools/packages/container/remote-kotlin-daemon-containers) under the `Kotlin Build Tools`.

Few useful commands:
- get the jar file\
  `./gradlew --stop && ./gradlew clean && ./gradlew :kotlin-remote-daemon:installDist`
- build & push Docker image to the Space registry\
  `docker buildx build --platform linux/amd64,linux/arm64 --progress=plain -f compiler/daemon/remote-daemon/Dockerfile2 -t registry.jetbrains.team/p/kotlin-build-tools/remote-kotlin-daemon-containers/kotlin-remote-daemon-workaround:latest --push .`
- build Docker image for local testing\
  `docker build --platform=linux/amd64 -t kotlin-daemon:latest -f compiler/daemon/remote-daemon/Dockerfile2 .`
- pull the image from the Space registry\
  `docker pull registry.jetbrains.team/p/kotlin-build-tools/remote-kotlin-daemon-containers/kotlin-remote-daemon-workaround:latest`


When building image using [Dockerfile2](Dockerfile2), remember to build again the `.jar` before with the latest changes. It is a common source of issues.

### Kubernetes deployment
[Intellij Console](https://console.intellij.net/) offers three ways how to deploy apps to Kubernetes, namely `Google JIB`, `Skaffold + kubectl apply`, `Pure Skaffold`. As I did not want to deal with `Skaffold` and `TeamCity` stuff I decided to deploy directly from my local machine only using `Helm`. I did it with the help of this [guide](https://youtrack.jetbrains.com/articles/SRE-A-305/How-to-deploy-from-your-local-machine).

The existing helm chart included in the guide has one flaw. The `imagePullPolicy` is set to `IfNotPresent` which means that `k8s` deployment would not pull the image from the registry even when newer image is available.

To overcome this, the original `Helm` chart was unpacked to [compiler/daemon/remote-daemon/k8s/simple-app-customized] directory where `imagePullPolicy: Always` was added to the [values.yaml](k8s/simple-app-customized/values.yaml) file.

Also, configuration for `gRPC` and `WebSockets` protocols needs to be slightly different, that is to reason why we have two separate files, [grpc_values.yaml](k8s/grpc_values.yaml) and [websockets_values.yaml](k8s/websockets_values.yaml). Do diff to see the differences.

Useful commands for deployment using customized `Helm` chart:
- deploy `gPRC` version
    - `helm install remote-kotlin-daemon-grpc compiler/daemon/remote-daemon/k8s/simple-app-customized -f compiler/daemon/remote-daemon/k8s/grpc_values.yaml`
- remove `gRPC` version
    - `helm uninstall remote-kotlin-daemon-grpc`
- deploy `WebSockets` version
    - `helm install remote-kotlin-daemon-websockets compiler/daemon/remote-daemon/k8s/simple-app-customized -f compiler/daemon/remote-daemon/k8s/websockets_values.yaml`
- remove `WebSockets` version
    - `helm uninstall remote-kotlin-daemon-websockets`

In case any configuration is not working because a client cannot connect to the server, this port-forwarding command might help:
`kubectl port-forward svc/remote-kotlin-daemon-websockets 8000:8000 -n remote-compilation-ns`.

Sometimes the connection does not work right away after deployment because of some `DNS` related issues. Probably it just takes some time to propagate the changes.

#### gRPC Nginx issue
When doing benchmarks, I noticed that the `gRPC` server is almost twice as slow as the `WebSockets` server. I started investigating this issue, and after exchanging a few messages with a coworker from the `SRE` team, we think the problem likely lies in the `Nginx` configuration. It seems that Nginx might be interfering with the HTTP/2 protocol. The conversation can be followed at this [link](https://jetbrains.slack.com/archives/C01QA0S88N7/p1758800865498599).

## Cache
For caching we use a standard filesystem with the following folder structure:
- `/storage`
    - `/cache`
        - `/artifacts`
            - `/<file-fingerprint>`
        - `/tmp`

Caching in our app is primarily content-based. For computing the fingerprint, we use the `SHA-256` function. We cache multiple types of artifacts, namely:
- source files
- compiler plugins
- compiler outputs
- dependencies (.class, .jar, directories)

Fingerprints for source files and compiler plugins are calculated only using the file content.

In the case of a folder, we also hash the relative file paths of all files in the folder. The file paths are sorted alphabetically to preserve the unique hash.

Hashing compiler outputs is a bit more complicated. We cannot compute the fingerprint directly from the produced class files, we would not be able to retrieve the result from the cache without actually compiling it before and obtaining the hash from produced class files. Instead, we compute the fingerprint from the source files and compiler arguments.

Some artifacts are stored in two ways. For example, some compilation tasks produce `.jar` file. This file can be stored as a dependency, that means that we just compute the fingerprint of the file content. However, the same `.jar` file can also be stored as a compiler output. This means that we also compute fingerprint of source files and compiler arguments that produced this `.jar` file. Then in `\artifacts` folder we create a symlink to the original `.jar` file stored as dependency (fingerprint computed only using source file content).

## Auth
The current solution includes a simple authentication mechanism but only in the gRPC implementation.

1. The client encodes `username:password` using Base64 and sends it in the `Authorization` header, check [BasicHTTPAuthClient.kt](src/main/kotlin/client/core/BasicHTTPAuthClient.kt).
2. The server verifies the credential against the entries in [auth.json](src/main/kotlin/server/auth/auth.json).
3. If the credential is valid, the server retrieves the corresponding `userId` from [uuid.json](src/main/kotlin/server/auth/uuid.json).
4. This `userId` is then used to create a dedicated compilation workspace directory for that user.

Of course, this approach is very rudimentary and not properly secure. It would make sense to revisit authentication once the protocol has been chosen and the solution is ready to be integrated into the existing infrastructure.

## Compilation Workspace
Compilation workspace is a directory that contains all files that are needed for a compilation task. The directory structure is as follows:
- `/storage`
    - `/workspaces`
        - `/<user-id>`
            - `/<project-name>`
                - `/<client-absolute-path>`

Once a file is available for compilation, regardless of whether it was received over the network or retrieved from a cache, it is copied to the compilation workspace. Maybe a potential performance improvement would be to create a symlink to the file instead of copying it. After the files are copied, it is also necessary to modify all paths in the compiler arguments and compilation options.

For example, if an absolute path on the client side is `/Users/michal.svec/Desktop/kotlin/compiler/backend/src/org/jetbrains/kotlin/codegen/inline/FieldRemapper.kt`, this path will be mapped to `/storage/workspaces/<user-id>/<project-name>/Users/michal.svec/Desktop/kotlin/compiler/backend/src/org/jetbrains/kotlin/codegen/inline/FieldRemapper.kt`. This preservation of the original file structure from the client side makes the process less error-prone. The file paths themselves are also important. For example, a file path might be contained in a compiler message. When sending this message back to the client, we can then retrieve the original client path.

The `tmp` directory serves as temporary storage and is used for storing files that were just reconstructed from chunks. Afterward, these files are moved to the cache or a specific compilation workspace if needed. Potentially, we could eliminate the `tmp` directory by directly computing the hash from file chunks. Currently, however, we only support computing hashes from files.

## Known Issues & Missing Features
- **compilation target**
    - currently, only the `JVM` target is supported
- **compiler plugins**
    - only specific versions of compiler plugins are supported
    - there is a one-to-one correspondence between compiler plugins and compiler version
        - this means that providing an incompatible compiler plugin to the compiler will result in failure
        - the current workaround is located in the [libsworkaround](src/main/kotlin/server/libsworkaround) folder
            - if there is a certain plugin in compiler arguments, its path will be rewritten by the plugin located in the [libsworkaround](src/main/kotlin/server/libsworkaround) folder
    - probably proper solution would be to have multiple JVM processes with different versions of compiler, and the request should be roted to the appropriate process
- **incremental compilation limits**
    - currently we are computing snapshot only on a client
    - probably it would be good to compute them on a sever
    - possibly we could consider caching them
- **`jdk-home` argument**
    - the Kotlin compiler accepts a `jdk-home` argument
    - however, sending the entire JDK to the server is impractical due to its large size
    - an alternative approach that was considered was sending only the parts of the `JDK` that change across versions, however, this approach is fragile since there is no standardized method for doing so
    - the current workaround removes `jdk-home` from the compiler arguments, `JDK home` will be inferred from `JAVA_HOME` environment variable
        - if we install the latest `JDK` on the server and then with help of `jvm-target` tag we should be able to compile projects even for older versions of `JDK`

## How To Run
All testings have been conducted on the [Ktor](https://github.com/ktorio/ktor) project. Since this remote compilation server is not integrated with the existing infrastructure, we needed to establish a method for running large compilation tasks. The process is as follows:

### Standard compilation
1. clone the [Ktor](https://github.com/ktorio/ktor) repository
    - the last-tested commit ID: `af24a5a1a663d6c3c4fe36360a565fe17461b2d`
    - newer versions will likely fail due to incompatible compiler plugins
2. configure the build script
    - open the `build.gradle.kts` file in the Ktor project
    - add the following code to the file:
   ```kotlin
   tasks.register("assembleAllKotlin") {
       allprojects {
           dependsOn(
               tasks
                   .withType<org.jetbrains.kotlin.gradle.tasks.KotlinCompile>()
                   .matching { !it.name.lowercase().contains("android") }
           )
       }
   }
   ```
    - `android` related tasks are excluded as they require the `Android SDK` to be installed

3. generate compilation output
    - execute the following command to output all Kotlin compilation tasks along with compiler arguments to a file:
   ```bash
   ./gradlew --stop && ./gradlew clean && ./gradlew assembleAllKotlin --no-configuration-cache --rerun --no-build-cache --refresh-dependencies -Pkotlin.internal.compiler.arguments.log.level=warning -Pkotlin.incremental=false > output
   ```
4. copy the absolute path of the generated output file
5. configure the [Benchmark.kt](/src/main/kotlin/benchmark/Benchmark.kt)
    - compilation of the Ktor project can be invoked in the file [Benchmark.kt](/src/main/kotlin/benchmark/Benchmark.kt)
    - paste the copied path into the `getTask` function located within the `main()` function
    - `getTask()` is a utility function that will extract all required information from the file and return it as a `List<Task>` object
    - remember to change the `host` and `port` values to match your setup
6. change the current working directory (CWD) of [Benchmark.kt](/src/main/kotlin/benchmark/Benchmark.kt) configuration to `/kotlin/compiler/daemon/remote-daemon`
7. the main function is now ready to be run

### Incremental Compilation
In our solution, incremental compilation (IC) has its limitations, and testing it can be challenging since IC is stateful — each run depends on the results of the previous one. Unlike standard compilation, we have not automated IC testing.

To test IC manually:
1. run the server from [RemoteCompilationServer.kt](src/main/kotlin/server/core/RemoteCompilationServer.kt).
2. once the server is running, open [RemoteCompilationClient.kt](src/main/kotlin/client/core/RemoteCompilationClient.kt).
    - in the `main()` function, you will find code that can invoke incremental compilation
    - you just need to configure `IncrementalCompilationOptions` and set all required file paths

For an example of IC configuration, you can build a Ktor module with the following command:
```bash
./gradlew --stop && ./gradlew clean && ./gradlew :ktor-client-android:build --no-build-cache --rerun --info -Pkotlin.internal.compiler.arguments.log.level=warning > icbuild
```
### Incremental Compilation
In our solution, incremental compilation (IC) has its limitations, and testing it can be challenging since IC is stateful — each run depends on the results of the previous one. Unlike standard compilation, we have not automated IC testing.

To test IC manually:
1. run the server from [RemoteCompilationServer.kt](src/main/kotlin/server/core/RemoteCompilationServer.kt).
2. once the server is running, open [RemoteCompilationClient.kt](src/main/kotlin/client/core/RemoteCompilationClient.kt).
    - in the `main()` function, you will find code that can invoke incremental compilation
    - you just need to configure `IncrementalCompilationOptions` and set all required file paths

For an example of IC configuration, you can build a Ktor module with the following command:
```bash
./gradlew --stop && ./gradlew clean && ./gradlew :ktor-client-android:build --no-build-cache --rerun --info -Pkotlin.internal.compiler.arguments.log.level=warning > icbuild
```